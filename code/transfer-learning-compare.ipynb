{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12d2452e",
   "metadata": {},
   "source": [
    "This work is inspired blog post of Maciej D. Korzec https://towardsdatascience.com/recommending-similar-images-using-pytorch-da019282770c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports, which were needed to run the code on the Puhti supercomputer\n",
    "# Install these via pip if you don't have them already\n",
    "'''\n",
    "import sys\n",
    "!{sys.executable} -m pip install torchvision\n",
    "!{sys.executable} -m pip install tqdm\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a448f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "from numpy.testing import assert_almost_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f48a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Needed input dimensions for the CNN\n",
    "# PyTorch's documentation suggests resolution of at least 224 x 224\n",
    "inputDim = (224,224)\n",
    "\n",
    "# Directory, from where the images to be analyzed are taken\n",
    "# Change accordingly to your needs and folder structure\n",
    "inputDir = \"ill_copy_new_clip/microbio\"\n",
    "\n",
    "# Output directory for the similar images\n",
    "# Change accordingly to your needs and folder structure\n",
    "inputDirCNN = \"CNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e045a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(inputDirCNN, exist_ok = True)\n",
    "\n",
    "transformationForCNNInput = transforms.Compose([transforms.Resize(inputDim)])\n",
    "\n",
    "# This will take reasonably large amount of time.\n",
    "# Could be investigated, if can be made faster\n",
    "\n",
    "for imageName in os.listdir(inputDir):\n",
    "    I = Image.open(os.path.join(inputDir, imageName))\n",
    "    newI = transformationForCNNInput(I)\n",
    "\n",
    "    # Copy the rotation information metadata from original image and save, else your transformed images may be rotated\n",
    "    newI.save(os.path.join(inputDirCNN, imageName))\n",
    "    \n",
    "    newI.close()\n",
    "    I.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class for the resnet\n",
    "class Img2VecResnet18():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # If you dont have an access to a GPU, use the CPU version\n",
    "        self.device = torch.device(\"cpu\") \n",
    "        # self.device = torch.device(\"cuda\") \n",
    "        self.numberFeatures = 512\n",
    "        self.modelName = \"resnet-18\"\n",
    "        self.model, self.featureLayer = self.getFeatureLayer()\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "        \n",
    "        # These values are suggested by PyTorch's documentation\n",
    "        # normalize the resized images as expected by resnet18\n",
    "        # [0.485, 0.456, 0.406] --> normalized mean value of ImageNet, [0.229, 0.224, 0.225] std of ImageNet\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "    def getVec(self, img):\n",
    "        image = self.normalize(self.toTensor(img)).unsqueeze(0).to(self.device)\n",
    "        embedding = torch.zeros(1, self.numberFeatures, 1, 1)\n",
    "\n",
    "        def copyData(m, i, o): embedding.copy_(o.data)\n",
    "\n",
    "        h = self.featureLayer.register_forward_hook(copyData)\n",
    "        self.model(image)\n",
    "        h.remove()\n",
    "\n",
    "        return embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    def getFeatureLayer(self):\n",
    "        cnnModel = models.resnet18(pretrained=True)\n",
    "        layer = cnnModel._modules.get('avgpool')\n",
    "        self.layer_output_size = 512\n",
    "        \n",
    "        return cnnModel, layer\n",
    "        \n",
    "\n",
    "# generate vectors for all the images in the set\n",
    "img2vec = Img2VecResnet18() \n",
    "\n",
    "allVectors = {}\n",
    "print(\"Converting images to feature vectors:\")\n",
    "for image in tqdm(os.listdir(inputDirCNN)):\n",
    "    I = Image.open(os.path.join(inputDirCNN, image)).convert(\"RGB\")\n",
    "    vec = img2vec.getVec(I)\n",
    "    allVectors[image] = vec\n",
    "    I.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290848c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us define a function that calculates the cosine similarity entries in the similarity matrix\n",
    "def getSimilarityMatrix(vectors):\n",
    "    v = np.array(list(vectors.values())).T\n",
    "    sim = np.inner(v.T, v.T) / ((np.linalg.norm(v, axis=0).reshape(-1,1)) * ((np.linalg.norm(v, axis=0).reshape(-1,1)).T))\n",
    "    keys = list(vectors.keys())\n",
    "    matrix = pd.DataFrame(sim, columns = keys, index = keys)\n",
    "    \n",
    "    return matrix\n",
    "        \n",
    "similarityMatrix = getSimilarityMatrix(allVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of top similar images to be stored\n",
    "k = 5\n",
    "\n",
    "similarNames = pd.DataFrame(index = similarityMatrix.index, columns = range(k))\n",
    "similarValues = pd.DataFrame(index = similarityMatrix.index, columns = range(k))\n",
    "\n",
    "for j in tqdm(range(similarityMatrix.shape[0])):\n",
    "    kSimilar = similarityMatrix.iloc[j, :].sort_values(ascending = False).head(k)\n",
    "    similarNames.iloc[j, :] = list(kSimilar.index)\n",
    "    similarValues.iloc[j, :] = kSimilar.values\n",
    "similarNames_path = \"similarNames.pkl\"\n",
    "similarValues_path = \"similarValues.pkl\"\n",
    "similarNames.to_pickle(similarNames_path)\n",
    "similarValues.to_pickle(similarValues_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "file = open(similarNames_path, 'rb')\n",
    "simNames = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(similarValues_path, 'rb')\n",
    "simValues = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0db8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAxes(ax, image, query = False, **kwargs):\n",
    "    value = kwargs.get(\"value\", None)\n",
    "    if query:\n",
    "        ax.set_xlabel(\"Query Image\\n{0}\".format(image), fontsize = 8)\n",
    "    else:\n",
    "        ax.set_xlabel(\"Similarity value {1:1.3f}\\n{0}\".format( image,  value), fontsize = 8)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "def getSimilarImages(image, simNames, simVals):\n",
    "    cutoff_value = 0.93\n",
    "    filtered = simVals[simVals > cutoff_value]\n",
    "    if image in set(simNames.index):\n",
    "        imgs = list(simNames.loc[image, :])\n",
    "        vals = list(filtered.loc[image, :])\n",
    "        if image in imgs:\n",
    "            assert_almost_equal(max(vals), 1, decimal = 5)\n",
    "            imgs.remove(image)\n",
    "            vals.remove(max(vals))\n",
    "        return imgs, vals\n",
    "    else:\n",
    "        print(\"'{}' Unknown image\".format(image))\n",
    "        \n",
    "def plotSimilarImages(image, similarNames, similarValues):\n",
    "    simImages, simValues = getSimilarImages(image, similarNames, similarValues)\n",
    "    fig = plt.figure(figsize=(10, 20))\n",
    "    \n",
    "    # cut-off value, which determines how similar images we want\n",
    "    cutoff_value = 0.93\n",
    "    whole_data = []\n",
    "\n",
    "    # now plot the  most simliar images\n",
    "    for j in range(0, numCol*numRow):\n",
    "        ax = []\n",
    "        if j == 0:\n",
    "            img = Image.open(os.path.join(inputDir, image))\n",
    "            ax = fig.add_subplot(numRow, numCol, 1)\n",
    "            setAxes(ax, image, query = True)\n",
    "        else:\n",
    "            # If not accurate enough, e.g,smaller than cutoff, dont print the image or write data \n",
    "            if simValues[j-1] < cutoff_value:\n",
    "                continue\n",
    "            img = Image.open(os.path.join(inputDir, simImages[j-1]))\n",
    "            ax.append(fig.add_subplot(numRow, numCol, j+1))\n",
    "            setAxes(ax[-1], simImages[j-1], value = simValues[j-1])\n",
    "            Dict = {\"original_image\" : image, \"similar_image\": simImages[j-1], \"similarity_score\": simValues[j-1]}\n",
    "            whole_data.append(Dict)\n",
    "        \n",
    "        img = img.convert('RGB')\n",
    "        plt.imshow(img)\n",
    "        img.close()\n",
    "\n",
    "    plt.show()\n",
    "    return whole_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1882c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image_data_to_csv(list_of_dicts):\n",
    "    with open('microbio_similarities.csv', 'a') as csvfile:\n",
    "        field_names = [\"original_image\", \"similar_image\", \"similarity_score\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        for i in list_of_dicts:\n",
    "            writer.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5688f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(results_list_of_dicts):\n",
    "    pass\n",
    "    # data = pd.DataFrame.from_dict(results_list_of_dicts, index)\n",
    "    # print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# take three examples from the provided image set and plot\n",
    "folder_path = \"ill_copy_new_clip/microbio\"\n",
    "numCol = 5\n",
    "numRow = 1\n",
    "num_files = 1000\n",
    "all_files = os.listdir(folder_path)\n",
    "# Shuffle the list of files randomly\n",
    "random.shuffle(all_files)\n",
    "selected_files = all_files[:num_files]\n",
    "\n",
    "results = list()\n",
    "\n",
    "for image in selected_files:\n",
    "    imgs, vals = getSimilarImages(image, simNames, simValues)\n",
    "    for x in range(0, len(imgs)):\n",
    "        if pd.isna(vals[x]):\n",
    "            continue\n",
    "        Dict = {\"original_image\" : image, \"similar_image\" : imgs[x], \"similarity_score\" : vals[x]}\n",
    "        results.append(Dict)\n",
    "\n",
    "write_image_data_to_csv(results)\n",
    "\n",
    "process_data(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ba621",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc0207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
